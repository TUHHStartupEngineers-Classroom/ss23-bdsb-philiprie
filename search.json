[
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "1 Challenge 1\nThe challenge was very similar to what was done in the introduction to the tidyverse beforehand and hence many parts of the code resemble the code that was shown in the chapter.\n\n# Sales by Location ----\n\n# Step 1 - Manipulate\nsales_by_loc_tbl <- bike_orderlines_wrangled_tbl %>%\n  select(state, total.price) %>%\n  group_by(state) %>%\n  summarize(sales = sum(total.price)) %>%\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\",\n                                     decimal.mark = \",\",\n                                     prefix = \"\",\n                                     suffix = \" € \"))\n\n# Step 2 - Visualize\nsales_by_loc_tbl %>%\n  \n  # Setup canvas with the columns year (x-axis) and sales (y-axis)\n  ggplot(aes(x = state, y = sales)) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  \n  # Geometries\n  geom_col(fill = \"#2DC6D6\") + # Use geom_col for a bar plot\n  #geom_label(aes(label = sales_text)) + # Adding labels to the bars\n  \n  # Formatting\n  # scale_y_continuous(labels = scales::dollar) + # Change the y-axis. \n  # Again, we have to adjust it for euro values\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title    = \"Revenue by state \",\n    subtitle = \"Total revenue of the years 2015 to 2019\",\n    x = \"\", # Override defaults for x and y\n    y = \"Revenue\"\n  )\n\n\n\n\n\n\n# Sales by Year and Location ----\n\n# Step 1 - Manipulate\nsales_by_year_loc_tbl <- bike_orderlines_wrangled_tbl %>%\n  select(order.date, total.price, state) %>%\n  mutate(year = year(order.date)) %>%\n  group_by(year, state) %>%\n  summarize(sales = sum(total.price)) %>%\n  ungroup() %>%\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\",\n                                     decimal.mark = \",\",\n                                     prefix = \"\",\n                                     suffix = \" € \"))\n# Step 2 - Visualize\nsales_by_year_loc_tbl %>%\n  \n  # Set up x, y, fill\n  ggplot(aes(x = year, y = sales, fill = state)) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  # Geometries\n  geom_col() + # Run up to here to get a stacked bar plot\n  geom_smooth(method = \"lm\", se = FALSE) + # Adding a trendline\n  \n  # Facet\n  facet_wrap(~ state) +\n  \n  # Formatting\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title = \"Revenue by year and location\",\n    subtitle = \"\",\n    fill = \"State\" # Changes the legend name\n  )\n\n\n\n\n\n\n#  Writing Files ----\n\nbike_orderlines_wrangled_tbl %>%\n  write_xlsx(\"01_tidyverse_files/01_bike_sales/02_wrangled_data/bike_orderlines.xlsx\")\n\n# CSV ----\nbike_orderlines_wrangled_tbl %>% \n  write_csv(\"01_tidyverse_files/01_bike_sales/02_wrangled_data/bike_orderlines.csv\")\n\n# RDS ----\nbike_orderlines_wrangled_tbl %>% \n  write_rds(\"01_tidyverse_files/01_bike_sales/02_wrangled_data/bike_orderlines.rds\")"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "1 Challenge 2.1\nFor the first challenge of this chapter I used an open API providing information about the population numbers of the United States over the past year. I decided to plot the number of inhabitants over the years to show the development.\n\n#import libraries\nlibrary(tidyverse)\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(RSQLite)\nlibrary(DBI)\n\n#access API\nresp <- GET(\"https://datausa.io/api/data?drilldowns=Nation&measures=Population\")\n\n#check if API responded successfully\nif (resp$status_code == 200) {\n  print(\"request has succeeded\")\n}\n\n#> [1] \"request has succeeded\"\n\n#extract information and form it into a tibble\nUS_data_lst <- resp %>%\n  .$content %>%\n  rawToChar() %>%\n  fromJSON()\n\ndata_lst <- US_data_lst[\"data\"]$data\ndata_tbl <- as_tibble(data_lst) %>%\n  select(Year, Population)\n\n#plot data\ndata_tbl %>%\n  ggplot(aes(x = Year, y = Population)) +\n  # Geometries\n  geom_col(fill = \"#2DC6D6\") + # Use geom_col for a bar plot\n  geom_smooth(method = \"lm\", se = FALSE) + # Adding a trendline\n  \n  # Formatting\n  # scale_y_continuous(labels = scales::dollar) + # Change the y-axis. \n  # Again, we have to adjust it for euro values\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \"\")) +\n  labs(\n    title    = \"US Population per year\",\n    x = \"\", # Override defaults for x and y\n    y = \"Inhabitants\"\n  )\n\n\n\n\n\n\n\n\n2 Challenge 2.2\nFor the second challenge, the goal was to create a small database of bike models (their names and prices) from one of Canyons rivaling companies, namely ROSE or Radon. Since I recently ordered a roadbike from ROSE, I went with their website. I confined myself to the category of roadbikes.\n\n#import libraries\nlibrary(tidyverse) \nlibrary(rvest)     \nlibrary(glue)      \n\n#scraping rose bikes for their road bike models\nhome_url <- \"https://www.rosebikes.com\"\nurl_roadbikes <- \"https://www.rosebikes.com/bikes/road\"\n\n#get the url of every model of the category road bike\nget_urls <- function(category_url){\n  \n  html_roadbikes <- read_html(category_url)\n  \n  bike_url_tbl <- html_roadbikes %>%\n    html_nodes(css = \".catalog-category-bikes__content > a\") %>%\n    html_attr(\"href\") %>%\n    enframe(name = \"position\", value = \"url\") %>%\n    mutate(url = glue(\"{home_url}{url}\"))\n  \n  return(bike_url_tbl)\n}\n\nbike_url_tbl <- get_urls(url_roadbikes)\n\n#get the name and price of each model\nget_bike_data <- function(url){\n  \n  html_model <- read_html(url)\n  \n  names <- html_model %>%\n    html_nodes(css = \".catalog-category-model__title\") %>%\n    html_text() %>%\n    str_trim() %>%\n    enframe(name = \"position\", value = \"name\")\n  \n  prices <- html_model %>%\n    html_nodes(css = \".catalog-category-model__price-current\") %>%\n    html_text() %>%\n    str_trim() %>%\n    enframe(name = \"position\", value = \"price\")\n  \n  bike_data <- names %>%\n    left_join(prices, by = join_by(position)) %>%\n    distinct(name, price)\n  \n  return(bike_data)\n}\n\ndatabase <- map(bike_url_tbl$url, get_bike_data)\ndatabase\n\n#> [[1]]\n#> # A tibble: 12 × 2\n#>    name                    price    \n#>    <chr>                   <chr>    \n#>  1 XLITE 04 105            €2,999.00\n#>  2 XLITE 04 Ultegra        €3,299.00\n#>  3 XLITE 04 105 Di2        €3,599.00\n#>  4 XLITE 04 Ultegra Di2    €4,599.00\n#>  5 XLITE 04 Force eTap AXS €4,599.00\n#>  6 XLITE 04 Force AXS      €4,999.00\n#>  7 XLITE 06 Ultegra        €3,999.00\n#>  8 XLITE 06 Ultegra Di2    €5,999.00\n#>  9 XLITE 06 Force eTap AXS €5,999.00\n#> 10 XLITE 06 Force AXS      €6,499.00\n#> 11 XLITE 06 Dura Ace Di2   €7,999.00\n#> 12 XLITE 06 Red eTap AXS   €8,199.00\n#> \n#> [[2]]\n#> # A tibble: 3 × 2\n#>   name                price    \n#>   <chr>               <chr>    \n#> 1 PRO SL 105          €1,099.00\n#> 2 PRO SL DISC 105     €1,699.00\n#> 3 PRO SL DISC Ultegra €1,999.00\n#> \n#> [[3]]\n#> # A tibble: 9 × 2\n#>   name                            price    \n#>   <chr>                           <chr>    \n#> 1 REVEAL FOUR DISC 105            €2,499.00\n#> 2 REVEAL FOUR DISC Ultegra        €2,799.00\n#> 3 REVEAL FOUR DISC 105 Di2        €3,299.00\n#> 4 REVEAL FOUR DISC Ultegra Di2    €3,999.00\n#> 5 REVEAL FOUR DISC Force eTap AXS €4,299.00\n#> 6 REVEAL SIX DISC Ultegra         €3,799.00\n#> 7 REVEAL SIX DISC ULTEGRA Di2     €4,799.00\n#> 8 REVEAL SIX DISC Dura Ace Di2    €6,999.00\n#> 9 REVEAL SIX DISC Red eTap AXS    €7,499.00"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "1 Challenge 3\nThe aim of this challenge was to further improve the ability of data wrangling. For this data by the USPTO was used. I decided to use the reduced dataset, since the computational capabilities of the laptop I am working on are limited.\n\n#import libraries----\nlibrary(tidyverse)\nlibrary(vroom)\nlibrary(data.table)\nlibrary(tidyr)\n#import reduced data set----\n\n#patent.tsv\ncol_types <- list(\n  id = col_character(),\n  date = col_date(\"%Y-%m-%d\"),\n  num_claims = col_double()\n)\n\npatent_tbl <- vroom(\n  file       = \"patent.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n# assignee.tsv\n\ncol_types <- list(\n  id = col_character(),\n  type = col_number(),\n  organization = col_character()\n)\n\nassignee_tbl <- vroom(\n  file       = \"assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n# patent_assignee.tsv\n\ncol_types <- list(\n  patent_id = col_character(),\n  assignee_id = col_character()\n)\n\npatent_assignee_tbl <- vroom(\n  file       = \"patent_assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n# uspc.tsv\n\ncol_types <- list(\n  patent_id = col_character(),\n  mainclass_id = col_character(),\n  sequence = col_double()\n)\n\nuspc_tbl <- vroom(\n  file       = \"uspc.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n#patent dominance ----\n#match the assigners to their patents\npatent_assignee_joined_tbl <- patent_assignee_tbl %>% \n  left_join(assignee_tbl, by = c(\"assignee_id\" = \"id\"))\n\n#filter for US companies (type=2), group and count the number of patents and then reorganize\npatent_us_tbl <- patent_assignee_joined_tbl %>%\n  filter(type == 2) %>%\n  group_by(organization) %>%\n  summarise(count = n()) %>%\n  ungroup() %>%\n  arrange(desc(count))\n\npatent_us_tbl %>%  head(n = 10)\n\n\n\n  \n\n\n#recent patent activity ----\n#add the date and number of claims to the tibble in order to be able to filter for August 2014\npatent_august14_tbl <- patent_assignee_joined_tbl %>% \n  left_join(patent_tbl, by = c(\"patent_id\" = \"id\"))\n\n#split the date category\npatent_august14_ymd_tbl <- patent_august14_tbl %>%\n  mutate(day  = lubridate::day(date), month = lubridate::month(date), year = lubridate::year(date))\n  \n#Somehow the method with separate() did not work\n#separate(col = date,\n#           into = c(\"year\", \"month\", \"day\"),\n#           sep = \"-\")\n\n#repeat the steps from the first task plus an additional filter for the year and month\npatent_august_tbl <- patent_august14_ymd_tbl %>%\n  filter(year == 2014) %>%\n  filter(month == 08) %>%\n  filter(type ==2) %>%\n  group_by(organization) %>%\n  summarise(count = n()) %>%\n  ungroup() %>%\n  arrange(desc(count))\n\npatent_august_tbl %>%  head(n = 10)\n\n\n\n  \n\n\n#innovation in tech ----\n#add uspc tibble which includes the different classes of patents\npatent_inno_tbl <- left_join(patent_assignee_joined_tbl,uspc_tbl)\n\n#find top10 worldwide (types 2 or 3)\ntop10_tbl <- patent_inno_tbl %>%\n  filter(type == 2 | type == 3) %>%\n  group_by(organization) %>%\n  summarise(count = n()) %>%\n  ungroup() %>%\n  arrange(desc(count)) %>%\n  head(n=10)\n  \n#find the 5 top main classes\ntop5_classes_tbl <- patent_inno_tbl %>%\n  filter( organization %in% top10_tbl$organization,  !is.na(mainclass_id)) %>%\n  group_by(mainclass_id) %>%\n  summarise(count_class = n()) %>%\n  ungroup() %>%\n  arrange(desc(count_class)) %>%  \n  select(mainclass_id) %>%\n  head(n = 5)\n\ntop5_classes_tbl"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "1 Challenge 4.1\n\nlibrary(tidyverse)\nlibrary(data.table)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(ggrepel)\nlibrary(glue)\n\ncovid_data_tbl <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\") %>%\n  select(location, date, total_cases) %>%\n  filter(location %in% c(\"Europe\", \"Germany\", \"United Kingdom\", \"France\", \"Spain\", \"United States\"))\n\ncovid_data_tbl %>%\n  \n  #plot cases over date\n  ggplot(aes(x = date, y = total_cases, color = location)) +\n  \n  #line plot\n  geom_line() +\n  \n  #scales for the x and y axis\n  scale_x_date(labels = scales::label_date(format = \"%b '%y\"), date_breaks = \"1 month\") +\n  scale_y_continuous(labels = scales::label_number(scale = 1e-6, prefix = \"\", suffix = \" M\")) +\n  \n  #add axis labels and title\n  labs(\n    title = \"COVID-19 confirmed cases worldwide\",\n    subtitle = glue(\"As of {date}\",\n                    date=format(max(covid_data_tbl$date),\"%d/%m/%Y\")),\n    caption = \"Challenge 1\",\n    x = \"\",\n    y = \"Cumulative Cases\",\n    color = \"Continent / Country\",\n  )+\n  \n  #choose minimal theme and modify\n  theme_minimal()+\n  theme(legend.position = \"bottom\",\n        plot.caption.position = \"plot\",\n        plot.caption = element_text(hjust = 0.5, size = 12),\n        axis.text.x = element_text(angle = 45, hjust =1),\n        plot.title = element_text(size=12),\n        plot.subtitle  = element_text(size=9),\n        legend.text = element_text(size = 7),\n        legend.title = element_text(size = 9),\n        )\n\n\n\n\n\n\n\n\n2 Challenge 4.2\nI had some difficulties with this task. As can be seen from the plot, for some countries no values for the death rate could be obtained. These regions for which the entry at the death rate then is na, are colored gray.\n\nlibrary(\"tidyverse\")\nlibrary(\"readxl\")\nlibrary(\"lubridate\")\nlibrary(\"data.table\")\nlibrary(\"vroom\")\nlibrary(\"scales\")\nlibrary(\"ggthemes\")\nlibrary(\"gapminder\")\nlibrary(\"ggplot2\")\nlibrary(\"forcats\")\nlibrary(\"readxl\")\nlibrary(\"ggrepel\")\nlibrary(\"glue\")\n\nworld <- map_data(\"world\")\n\ncovid_data <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\") %>%\n  mutate(location = case_when(\n    \n    location == \"United Kingdom\" ~ \"UK\",\n    location == \"United States\" ~ \"USA\",\n    location == \"Democratic Republic of Congo\" ~ \"Democratic Republic of the Congo\",\n    TRUE ~ location\n    \n  )) %>%\n  distinct() %>%\n  group_by(location) %>%\n  slice(which.max(as.Date(date))) %>%\n  select(location, total_deaths, population,date) %>%\n  mutate(death_rate = total_deaths/population)\n\ncov_data_world <-  world %>%\n  left_join(covid_data, by = c(\"region\"=\"location\")) %>%\n  select(long, lat, group, order, region, subregion, everything())\n  \ncov_data_world %>% ggplot() +\n  geom_map( aes(long, lat, map_id = region, fill = death_rate), \n            map = cov_data_world,\n            color = \"grey\",\n            size = 0.09\n  )+\n  scale_fill_gradient(low = \"#FFC6C6\", high = \"#FF0000\", na.value = \"grey\")"
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "Welcome! This website functions as the lab journal for the Business Data Science Basics module. In the menu above you can find the journals I have prepared for the four different chapters and the challenges each presented. I hope that the results presented match the criteria for passing this class, some challenges turned out to be quite tough, but overall they helped in the understanding and were interesting. I had some difficulties with the last challenge, where a world map was to be plotted, I hope that is not an issue.\nI did not alter the files for the Class notes nor the Links."
  }
]